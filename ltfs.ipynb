{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "\n",
    "train = pd.read_csv('../input/ltfs-finhack-av-competition/train.csv')\n",
    "test = pd.read_csv('../input/ltfs-finhack-av-competition/test.csv')\n",
    "\n",
    "#Getting shapes of dataset\n",
    "print(\"Train shape: \",train.shape)\n",
    "print(\"Test shape: \",test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = test['unique_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable\n",
    "#Loan default is the failure to repay a loan according to the terms agreed to in the promissory note.\n",
    "\n",
    "print(train['loan_default'].value_counts(normalize=True))\n",
    "train['loan_default'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate analysis - to see distribution of data and detect outliers if any\n",
    "#Categorical features - Employement type\n",
    "\n",
    "train['employment_type'].value_counts().plot.bar(figsize=(10,5),title='Employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical features\n",
    "train['disbursed_amt'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis-1 \n",
    "Higher cns_score better score --> loan_default 0 (able to pay loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cns_score'].describe()\n",
    "train['cns_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train['employment_type'],train['loan_default'],normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = train.corr()\n",
    "correlation['aadhar_flag'].sort_values(ascending=False) #voderid -0.8 correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.copy()\n",
    "test_data = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['voderid_flg'], axis=1, inplace=True)\n",
    "test_data.drop(['voderid_flg'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.loc[['aadhar_flag','pan_flag','driving_flag','passport_flag','voderid_flg'],\n",
    "                ['aadhar_flag','pan_flag','driving_flag','passport_flag','voderid_flg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation['pri_disbursed_amt'].sort_values(ascending=False)#drop pri_sanctionedamt corr-0.998747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['pri_sanctioned_amt'],axis=1,inplace=True)\n",
    "test_data.drop(['pri_sanctioned_amt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking all flags\n",
    "print(train_data['mobileno_avl_flag'].value_counts())  #varianc=0 drop variable\n",
    "print(train_data['aadhar_flag'].value_counts()) \n",
    "print(train_data['pan_flag'].value_counts()) \n",
    "print(train_data['voderid_flg'].value_counts()) \n",
    "print(train_data['driving_flag'].value_counts()) \n",
    "print(train_data['passport_flag'].value_counts()) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['mobileno_avl_flag'],axis=True,inplace=True)\n",
    "test_data.drop(['mobileno_avl_flag'],axis=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(train['employment_type'].value_counts())\n",
    "\n",
    "print(train['employment_type'].mode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling nan values\n",
    "train['employment_type'].fillna(train['employment_type'].mode()[0], inplace=True)\n",
    "test['employment_type'].fillna(train['employment_type'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date of birth is an useless attribute \n",
    "#  the only thing we can extract the is the year of birth and from that 'age' feature can be generated.\n",
    "# let's first convert the date into date-time format\n",
    "\n",
    "\n",
    "train_data['date_of_birth'] = pd.to_datetime(train_data['date_of_birth'], errors='coerce')\n",
    "train_data['disbursal_date'] = pd.to_datetime(train_data['disbursal_date'], errors='coerce')\n",
    "\n",
    "test_data['date_of_birth'] = pd.to_datetime(test_data['date_of_birth'], errors='coerce')\n",
    "test_data['disbursal_date'] = pd.to_datetime(test_data['disbursal_date'], errors='coerce')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering\n",
    "# Age feature in years\n",
    "train_data['Age'] = train_data['disbursal_date'].dt.year - train_data['date_of_birth'].dt.year\n",
    "test_data['Age'] = test_data['disbursal_date'].dt.year - test_data['date_of_birth'].dt.year\n",
    "\n",
    "#month from disbursal date can be of use. Income tax months - repay loan, festivals - vehicle on loan\n",
    "train_data['disbursal_month'] = train_data['disbursal_date'].dt.month\n",
    "test_data['disbursal_month'] = test_data['disbursal_date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['Age'].head(12))\n",
    "print(test_data['Age'].head(12))\n",
    "print(train_data['disbursal_month'].head(12))\n",
    "print(test_data['disbursal_month'].head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['date_of_birth','disbursal_date'], axis=1, inplace=True)\n",
    "test_data.drop(['date_of_birth','disbursal_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting 'avg_account_age' and 'credit_history_length' into numerical features\n",
    "\n",
    "train_data['credit_history_length_years'] = train_data['credit_history_length'].apply(lambda x: x.split(' ')[0])\n",
    "train_data['credit_history_length_years'] = train_data['credit_history_length'].apply(lambda x: x.split('yrs')[0])\n",
    "\n",
    "test_data['credit_history_length_years'] = test_data['credit_history_length'].apply(lambda x: x.split(' ')[0])\n",
    "test_data['credit_history_length_years'] = test_data['credit_history_length'].apply(lambda x: x.split('yrs')[0])\n",
    "print(train_data['credit_history_length_years'].head(10))\n",
    "print(test_data['credit_history_length_years'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['credit_history_length_months'] = train_data['credit_history_length'].apply(lambda x: x.split(' ')[1])\n",
    "train_data['credit_history_length_months'] = train_data['credit_history_length_months'].apply(lambda x: x.split('mon')[0])\n",
    "\n",
    "test_data['credit_history_length_months'] = test_data['credit_history_length'].apply(lambda x: x.split(' ')[1])\n",
    "test_data['credit_history_length_months'] = test_data['credit_history_length_months'].apply(lambda x: x.split('mon')[0])\n",
    "print(train_data['credit_history_length_months'].head())\n",
    "print(test_data['credit_history_length_months'].head())\n",
    "                                                                                            \n",
    "                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting dtype from object to float\n",
    "train_data['credit_history_length_years']=train_data['credit_history_length_years'].astype('float')\n",
    "train_data['credit_history_length_months']=train_data['credit_history_length_months'].astype('float')\n",
    "\n",
    "test_data['credit_history_length_years']=test_data['credit_history_length_years'].astype('float')\n",
    "test_data['credit_history_length_months']=test_data['credit_history_length_months'].astype('float')\n",
    "#train_data['credit_history_length_years'] = train_data['credit_history_length_years'] * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['credit_history_length_months'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['credit_history_length_months'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['credit_history_length_months2'] = train_data['credit_history_length_months'].apply(lambda x: x/12)\n",
    "train_data['credit_history_length_months2'] = train_data['credit_history_length_months2'].round(decimals=2)\n",
    "\n",
    "\n",
    "train_data['credit_history_length_years'] =train_data['credit_history_length_years']+ train_data['credit_history_length_months2']\n",
    "train_data['credit_history_length_years'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['credit_history_length_months2'] = test_data['credit_history_length_months'].apply(lambda x: x/12)\n",
    "test_data['credit_history_length_months2'] = test_data['credit_history_length_months2'].round(decimals=2)\n",
    "\n",
    "test_data['credit_history_length_years'] =test_data['credit_history_length_years']+ test_data['credit_history_length_months2']\n",
    "test_data['credit_history_length_years'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data.drop(['credit_history_length','credit_history_length_months','credit_history_length_months2'], axis=1, inplace=True)\n",
    "test_data.drop(['credit_history_length','credit_history_length_months','credit_history_length_months2'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of avg_account_age attribute to numerical feature\n",
    "train_data['avg_account_age_years'] = train_data['avg_account_age'].apply(lambda x: x.split(' ')[0])\n",
    "train_data['avg_account_age_years'] = train_data['avg_account_age_years'].apply(lambda x: x.split('yrs')[0])\n",
    "\n",
    "print(train_data['avg_account_age_years'].head())\n",
    "print(train_data['avg_account_age'].head())\n",
    "\n",
    "test_data['avg_account_age_years'] = test_data['avg_account_age'].apply(lambda x: x.split(' ')[0])\n",
    "test_data['avg_account_age_years'] = test_data['avg_account_age_years'].apply(lambda x: x.split('yrs')[0])\n",
    "\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(test_data['avg_account_age_years'].head())\n",
    "print(test_data['avg_account_age'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['avg_account_age_months'] = train_data['avg_account_age'].apply(lambda x: x.split(' ')[1])\n",
    "train_data['avg_account_age_months'] = train_data['avg_account_age_months'].apply(lambda x: x.split('mon')[0])\n",
    "\n",
    "print(train_data['avg_account_age_months'].head())\n",
    "print(train_data['avg_account_age'].head())\n",
    "\n",
    "test_data['avg_account_age_months'] = test_data['avg_account_age'].apply(lambda x: x.split(' ')[1])\n",
    "test_data['avg_account_age_months'] = test_data['avg_account_age_months'].apply(lambda x: x.split('mon')[0])\n",
    "\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(test_data['avg_account_age_months'].head())\n",
    "print(test_data['avg_account_age'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting dtype from object to float\n",
    "train_data['avg_account_age_years']=train_data['avg_account_age_years'].astype('float')\n",
    "train_data['avg_account_age_months']=train_data['avg_account_age_months'].astype('float')\n",
    "\n",
    "test_data['avg_account_age_years']=test_data['avg_account_age_years'].astype('float')\n",
    "test_data['avg_account_age_months']=test_data['avg_account_age_months'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['avg_account_age_months'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion from months to accumulative years only\n",
    "train_data['avg_account_age_months2'] = train_data['avg_account_age_months'].apply(lambda x: x/12)\n",
    "train_data['avg_account_age_months2'] = train_data['avg_account_age_months2'].round(decimals=2)\n",
    "\n",
    "\n",
    "train_data['avg_account_age_years'] =train_data['avg_account_age_years']+ train_data['avg_account_age_months2']\n",
    "print(train_data['avg_account_age_years'].head())\n",
    "print(train_data['avg_account_age'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['avg_account_age_months2'] = test_data['avg_account_age_months'].apply(lambda x: x/12)\n",
    "test_data['avg_account_age_months2'] = test_data['avg_account_age_months2'].round(decimals=2)\n",
    "\n",
    "\n",
    "test_data['avg_account_age_years'] =test_data['avg_account_age_years']+ test_data['avg_account_age_months2']\n",
    "print(test_data['avg_account_age_years'].head())\n",
    "print(test_data['avg_account_age'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['avg_account_age','avg_account_age_months','avg_account_age_months2'],axis=1, inplace=True)\n",
    "test_data.drop(['avg_account_age','avg_account_age_months','avg_account_age_months2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['cns_score_description'].unique())\n",
    "print(train_data['cns_score_description'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encodings for bureau score(perform cns score distribution)\n",
    "\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('No Bureau History Available', 0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('Not Scored: Sufficient History Not Available', 0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('Not Scored: Not Enough Info available on the customer', 0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('Not Scored: No Activity seen on the customer (Inactive)',0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('Not Scored: No Updates available in last 36 months', 0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('Not Scored: Only a Guarantor', 0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('Not Scored: More than 50 active Accounts found',0)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('M-Very High Risk', 1)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('L-Very High Risk', 1)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('K-High Risk', 2)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('J-High Risk', 2)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('I-Medium Risk', 3)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('H-Medium Risk', 3)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('G-Low Risk', 4)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('F-Low Risk', 4)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('E-Low Risk', 4)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('D-Very Low Risk', 5)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('C-Very Low Risk', 5)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('B-Very Low Risk', 5)\n",
    "train_data['cns_score_description'] = train_data['cns_score_description'].replace('A-Very Low Risk', 5)\n",
    "\n",
    "# checing the values in bureau score\n",
    "train_data['cns_score_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding cns_score_description in test_data\n",
    "print(test_data['cns_score_description'].nunique())\n",
    "print(test_data['cns_score_description'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('No Bureau History Available', 0)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('Not Scored: Sufficient History Not Available', 0)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('Not Scored: Not Enough Info available on the customer', 0)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('Not Scored: No Activity seen on the customer (Inactive)',0)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('Not Scored: No Updates available in last 36 months', 0)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('Not Scored: Only a Guarantor', 0)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('M-Very High Risk', 1)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('L-Very High Risk', 1)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('K-High Risk', 2)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('J-High Risk', 2)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('I-Medium Risk', 3)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('H-Medium Risk', 3)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('G-Low Risk', 4)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('F-Low Risk', 4)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('E-Low Risk', 4)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('D-Very Low Risk', 5)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('C-Very Low Risk', 5)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('B-Very Low Risk', 5)\n",
    "test_data['cns_score_description'] = test_data['cns_score_description'].replace('A-Very Low Risk', 5)\n",
    "\n",
    "# checing the values in bureau score\n",
    "test_data['cns_score_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecesarry attributes\n",
    "train_data.drop(['unique_id','branch_id','supplier_id','manufacturer_id','current_pincode_id','state_id'], axis=1, inplace=True)\n",
    "test_data.drop(['unique_id','branch_id','supplier_id','manufacturer_id','current_pincode_id','state_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One -hot encodng for employement type feature\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train['loan_default']\n",
    "train_data.drop(['loan_default'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['loan_default'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying standardization\n",
    "\n",
    "# standardization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_data = sc.fit_transform(train_data)\n",
    "test_data = sc.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='saga')\n",
    "param_grid = {'C': [0.003,0.005,0.008,0.01,0.1,1], 'penalty': ['l1', 'l2']}\n",
    "gridsearch = GridSearchCV(clf, param_grid,cv=5,scoring='roc_auc',refit=True) \n",
    "#cross_val=5 , metric roc auc score,refit will refit model on whole dataset\n",
    "gridsearch.fit(train_data, label)\n",
    "print(gridsearch.best_params_)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' final val score:  0.6236535202253027  C-0.005\n",
    "    final val score:  0.6255618571430888  C-0.009\n",
    "    final val score:  0.6249658474263933  C-0.01\n",
    "    final val score:  0.6255209173762393  C-0.03\n",
    "    final val score:  0.6256649213065772  C-0.1\n",
    "    final val score:  0.6257040067515394  C-1.0\n",
    "    final val score:  0.625706716037291   C-10\n",
    "    final val score:  0.6257072031367716  C-100'''   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Models to Evaluate\n",
    "\n",
    "# We will compare five different machine learning Cassification models:\n",
    "\n",
    "# 1 - Logistic Regression\n",
    "# 2 - Suport Vector Machine\n",
    "# 3 - Random Forest Classification\n",
    "# 4 = XGboost\n",
    "\n",
    "# Function to calculate mean absolute error\n",
    "def cross_val(model):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    score = 0.0\n",
    "\n",
    "    # stratified k-fold technique\n",
    "    i=1\n",
    "    skf =  StratifiedKFold(n_splits=5,random_state=0)\n",
    "\n",
    "    for train_index, val_index in skf.split(train_data,label):\n",
    "        print('\\n{} of kfold {}'.format(i,skf.n_splits))\n",
    "        xtr,xval = train_data[train_index],train_data[val_index]\n",
    "        ytr,yval = label.loc[train_index],label.loc[val_index]\n",
    "\n",
    "        model.fit(xtr,ytr)\n",
    "        y_predicted = model.predict_proba(xval)\n",
    "        score = score + roc_auc_score(yval, y_predicted[:,1]) #Passing only prob of positive class\n",
    "\n",
    "        print('roc auc score: ',roc_auc_score(yval, y_predicted[:,1]))\n",
    "        i = i + 1\n",
    "\n",
    "    print('final val score: ',score/5)\n",
    "    \n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def predict_for_test(model):\n",
    "    \n",
    "   \n",
    "    # Let's predict for test set\n",
    "    test_predicted = model.predict_proba(test_data)\n",
    "    y_pred = test_predicted[:,1]\n",
    "    \n",
    "    \n",
    "    # Return the performance metric\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='saga')\n",
    "val_score = cross_val(lr)\n",
    "print('LR: ',val_score)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest Classification\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10)\n",
    "cross_val(rf)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradiente Boosting Classification\n",
    "from xgboost import XGBClassifier\n",
    "gb = XGBClassifier()\n",
    "cross_val(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_for_test(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  let's create a submission file\n",
    "\n",
    "#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n",
    "\n",
    "submission = pd.DataFrame({'UniqueID': unique_id,'loan_default': y_pred})\n",
    "\n",
    "#Visualize the first 5 rows\n",
    "submission.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "submission.to_csv('submission5_xgboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach in this kernel -\n",
    "drop certain features who had more correlation - voderid_flag, pri_sanctioned_amt\n",
    "drop mobileavl_flag - 0 variance\n",
    "new feature - disbursal_month\n",
    "\n",
    "tried random forest but not giving good performance. \n",
    "Model used - xgboost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
